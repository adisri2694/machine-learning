import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

dataset=pd.read_csv('aditya.csv')
dataset.insert(0, 'Ones', 1)

x=dataset.iloc[:,:-1]
y=dataset.iloc[:,-1].reshape(1599,1)
from sklearn import preprocessing
x = preprocessing.normalize(x)
print np.isnan(np.min(x))

from sklearn.cross_validation import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)



theta=np.zeros([1,x.shape[1]])
alpha=0.1
iterations=10000

def computeCost(x,y,theta):
    a = np.power((np.dot(x , theta.T)-y),2)
    return np.sum(a)/(2 * len(x))

def gradientDescent(x,y,theta,iters,alpha):
    cost = np.zeros(iters)
    cost= cost.reshape(10000,1)
    for i in range(iters):
        theta = theta - (alpha/len(x)) * np.sum(x * (np.dot(x , theta.T) - y), axis=0)
        cost[i] = computeCost(x, y, theta)
    
    return theta,cost

g,cost = gradientDescent(x_train,y_train,theta,iterations,alpha)
print(g)

finalCost = computeCost(x_train,y_train,g)
print(finalCost)

plt.plot(np.arange(10000),cost)

y_pd=(np.dot(g,x_test.T)).T

mean=(np.sum(y_test))/(y_test.shape[0])
print mean

SSres=np.sum(np.power((y_test-y_pd),2))
SStot=np.sum(np.power((y_test-mean),2))

score=1-(SSres/SStot)
print score

